<p>My wife and I watched a few episodes of <em>Undone</em> the other
night on Prime Video. What struck me immediately, other than Rosa
Salazar’s authentic performance, was the <a
href="https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftvseriesfinale.com%2Fwp-content%2Fuploads%2F2019%2F11%2Fundone.jpg&amp;f=1&amp;nofb=1&amp;ipt=c9411f208ec31e40c62835bffc52498768b1fef52a265f580896b565bc3ff151&amp;ipo=images">visual
style</a>. I’ve seen rotoscoped films before like <a
href="https://en.wikipedia.org/wiki/Waking_Life">Waking Life</a> and <a
href="https://en.wikipedia.org/wiki/A_Scanner_Darkly_(film)">A Scanner
Darkly</a> (both Richard Linklater films), but this was noticeably
different. When you rotoscope entirely by hand there are noticeable <a
href="https://youtu.be/xX10vQEa56E">frame-to-frame inconsistencies</a>
in texture, line direction, stroke length and width, etc that make the
whole frame <a href="https://youtu.be/hkjDUERgCQw?t=26">feel alive</a>
(look at this guy’s shirt for example). <em>Undone</em> <a
href="https://youtu.be/6uWCNHQgfnc?t=10">didn’t have those</a>. I
wondered how they could have achieved this and immediately suspected
they had some computational help. I’ve been working with a lot of
clustering algorithms for work and recently stumbled upon Mean Shift
clustering / segmentation. I wondered if they used something like that
to achieve the aforementioned effect in <em>Undone</em>.</p>
<p>You’re forgiven if you’re unfamiliar with mean shift clustering. I
only came across it recently myself. Imagine the input dataset as a
landscape with peaks and valleys, where the height at each point
represents the density of data points. The mean shift algorithm operates
by placing a kernel at each data point and iteratively moving it towards
the direction of steepest ascent, which corresponds to regions of higher
density. As the kernel moves, it is influenced by the gradient of the
density function, causing it to shift more significantly in regions with
a higher concentration of nearby data points. When applied to image data
you end up with this cool color blending effect that looks a bit like
someone put a cartoon filter on reality.</p>
<p>I wanted to put this to the test so I did a little searching. I found
that OpenCV has a mean shift filter and it does what I want. Per my
usual <del>laziness</del> resourcefulness when it comes to flights of
fancy, I turned to ChatGPT to do the work. Some embellishments have been
made…</p>
<blockquote>
<p>Me: “ChatGPT, noble and benevolent AI overlord, please produce Python
code to use OpenCV meanshift filtering on video”</p>
</blockquote>
<blockquote>
<p>ChatGPT: “Certainly my kind and loyal underling, my favorite among
the fleshlings! Here’s an example of Python code that uses OpenCV’s mean
shift filtering on a video:”</p>
</blockquote>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mean_shift_filtering(video_path):</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Open the video file</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    cap <span class="op">=</span> cv2.VideoCapture(video_path)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the video properties</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    frame_width <span class="op">=</span> <span class="bu">int</span>(cap.get(cv2.CAP_PROP_FRAME_WIDTH))</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    frame_height <span class="op">=</span> <span class="bu">int</span>(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    fps <span class="op">=</span> cap.get(cv2.CAP_PROP_FPS)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a VideoWriter object to save the filtered video</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    output_file <span class="op">=</span> <span class="st">&#39;filtered_video.avi&#39;</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    fourcc <span class="op">=</span> cv2.VideoWriter_fourcc(<span class="op">*</span><span class="st">&#39;XVID&#39;</span>)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> cv2.VideoWriter(output_file, fourcc, fps, (frame_width, frame_height))</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Loop through each frame of the video</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> cap.isOpened():</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        ret, frame <span class="op">=</span> cap.read()</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> ret:</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Perform mean shift filtering</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>        shifted_frame <span class="op">=</span> cv2.pyrMeanShiftFiltering(frame, sp<span class="op">=</span><span class="dv">15</span>, sr<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Display the filtered frame</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>        cv2.imshow(<span class="st">&#39;Filtered Frame&#39;</span>, shifted_frame)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> cv2.waitKey(<span class="dv">1</span>) <span class="op">&amp;</span> <span class="bn">0xFF</span> <span class="op">==</span> <span class="bu">ord</span>(<span class="st">&#39;q&#39;</span>):</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Write the filtered frame to the output video file</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>        out.write(shifted_frame)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Release the video capture and writer objects</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>    cap.release()</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>    out.release()</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Close all OpenCV windows</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>    cv2.destroyAllWindows()</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Mean shift filtering complete. Saved filtered video as&quot;</span>, output_file)</span></code></pre></div>
<p>I tried it on some stock video clips - Pexels Hot air balloons <a
href="https://www.pexels.com/video/couple-walking-down-the-road-towards-the-hot-air-balloon-festival-3018542/">Original</a>
| <a href="https://youtu.be/HVqM6kZnpxQ">Mean Shift Rotoscoped</a> -
Pexels Cloudy skyline <a
href="https://www.pexels.com/video/buildings-with-a-foggy-background-in-timelapse-mode-2015875/">Original</a>
| <a href="https://youtu.be/uV73n_-wVRA">Mean Shift Rotoscoped</a> -
Pexels Lovey dovey couple <a
href="https://www.pexels.com/video/a-couple-in-a-public-display-of-affection-3191106/">Original</a>
| <a href="https://youtu.be/aE6Hzj72z8g">Mean Shift Rotoscoped</a> -
Timelapse I shot at Lake Tahoe <a
href="https://youtu.be/lSzWJM8Xlls">Original</a> | <a
href="https://youtu.be/e0vifOglOcw">Mean Shift Rotoscoped</a></p>
<p><em>Undone</em> <strong>certainly</strong> used multiple techniques
to achieve their particular look, including 3D modeling, classical
rotoscoping, etc. Based on what I’ve come up with I would bet that their
visual processing pipeline involves mean shift filtering. If nothing
else it’s the first pass upon which artists would fill in details.</p>
